{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704d8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: /Users/sultan/DataScience/LLM-From-Scratch-Project/.venv/bin/python\n",
      "Torch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Añadimos la raíz del proyecto al path de Python\n",
    "PROJECT_ROOT = \"/Users/sultan/DataScience/LLM-From-Scratch-Project\"\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.model.attention import (\n",
    "    create_causal_mask,\n",
    "    scaled_dot_product_attention,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "\n",
    "from src.model.layers import (\n",
    "    TokenEmbedding,\n",
    "    PositionalEmbedding,\n",
    "    FeedForward,\n",
    "    LayerNorm,\n",
    ")\n",
    "\n",
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f474d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q shape: torch.Size([1, 1, 4, 2])\n",
      "k shape: torch.Size([1, 1, 4, 2])\n",
      "v shape: torch.Size([1, 1, 4, 2])\n",
      "out shape: torch.Size([1, 1, 4, 2])\n",
      "attn shape: torch.Size([1, 1, 4, 4])\n",
      "\n",
      "Causal mask (0 = futuro bloqueado):\n",
      "tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "\n",
      "Attention matrix (head 0):\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5846, 0.4154, 0.0000, 0.0000],\n",
      "        [0.2029, 0.6149, 0.1822, 0.0000],\n",
      "        [0.1886, 0.0650, 0.1352, 0.6112]])\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_heads, seq_len, head_dim = 1, 1, 4, 2\n",
    "\n",
    "q = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "k = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "v = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "mask = create_causal_mask(seq_len, device=q.device)\n",
    "\n",
    "out, attn = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "\n",
    "print(\"q shape:\", q.shape)\n",
    "print(\"k shape:\", k.shape)\n",
    "print(\"v shape:\", v.shape)\n",
    "print(\"out shape:\", out.shape)\n",
    "print(\"attn shape:\", attn.shape)\n",
    "print(\"\\nCausal mask (0 = futuro bloqueado):\")\n",
    "print(mask[0, 0].int())\n",
    "print(\"\\nAttention matrix (head 0):\")\n",
    "print(attn[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322d6369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 8])\n",
      "Output shape: torch.Size([2, 5, 8])\n",
      "Attention shape: torch.Size([2, 2, 5, 5])\n",
      "\n",
      "Attention matrix (batch 0, head 0):\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3857, 0.6143, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2425, 0.3793, 0.3782, 0.0000, 0.0000],\n",
      "        [0.2708, 0.1764, 0.2611, 0.2917, 0.0000],\n",
      "        [0.2018, 0.2011, 0.1663, 0.2144, 0.2164]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, embed_dim, num_heads = 2, 5, 8, 2\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, embed_dim)\n",
    "mha = MultiHeadAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "\n",
    "mask = create_causal_mask(seq_len, device=x.device)\n",
    "\n",
    "out, attn = mha(x, mask=mask)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(\"Attention shape:\", attn.shape)\n",
    "print(\"\\nAttention matrix (batch 0, head 0):\")\n",
    "print(attn[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f119f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token emb shape: torch.Size([2, 10, 8])\n",
      "Pos emb shape: torch.Size([2, 10, 8])\n",
      "Sum shape: torch.Size([2, 10, 8])\n",
      "\n",
      "Example token embedding[0,0]: tensor([ 1.3288, -2.4420,  1.1842, -0.8649, -6.8487,  0.9799,  0.6968, -0.2026],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Example pos embedding[0,0]: tensor([ 1.3486, -2.1934,  0.7030,  0.8502, -0.6056, -0.5264, -0.4830, -1.2382],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50\n",
    "max_seq_len = 16\n",
    "embed_dim = 8\n",
    "batch_size, seq_len = 2, 10\n",
    "\n",
    "ids = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "tok_emb = TokenEmbedding(vocab_size, embed_dim)\n",
    "pos_emb = PositionalEmbedding(max_seq_len, embed_dim)\n",
    "\n",
    "t = tok_emb(ids)\n",
    "p = pos_emb(ids)\n",
    "s = t + p\n",
    "\n",
    "print(\"Token emb shape:\", t.shape)\n",
    "print(\"Pos emb shape:\", p.shape)\n",
    "print(\"Sum shape:\", s.shape)\n",
    "print(\"\\nExample token embedding[0,0]:\", t[0, 0])\n",
    "print(\"Example pos embedding[0,0]:\", p[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc33562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 8])\n",
      "FFN output shape: torch.Size([2, 5, 8])\n",
      "LayerNorm output shape: torch.Size([2, 5, 8])\n",
      "\n",
      "Mean over last dim before LN (first token): -0.17933684587478638\n",
      "Std over last dim before LN (first token): 0.2778705060482025\n",
      "\n",
      "Mean over last dim after LN (first token): 1.4901161193847656e-08\n",
      "Std over last dim after LN (first token): 0.9999353289604187\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = 2, 5, 8\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "ff = FeedForward(d_model)\n",
    "ln = LayerNorm(d_model)\n",
    "\n",
    "y = ff(x)\n",
    "z = ln(y)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"FFN output shape:\", y.shape)\n",
    "print(\"LayerNorm output shape:\", z.shape)\n",
    "\n",
    "# Opcional: ver medias y desviaciones por posición\n",
    "print(\"\\nMean over last dim before LN (first token):\", y[0, 0].mean().item())\n",
    "print(\"Std over last dim before LN (first token):\", y[0, 0].std(unbiased=False).item())\n",
    "\n",
    "print(\"\\nMean over last dim after LN (first token):\", z[0, 0].mean().item())\n",
    "print(\"Std over last dim after LN (first token):\", z[0, 0].std(unbiased=False).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fdc1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([2, 10, 8])\n",
      "Attention weights shape: torch.Size([2, 2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Mini pipeline: ids -> embeddings -> MHA -> FFN + LN\n",
    "\n",
    "vocab_size = 50\n",
    "max_seq_len = 16\n",
    "embed_dim = 8\n",
    "num_heads = 2\n",
    "batch_size, seq_len = 2, 10\n",
    "\n",
    "ids = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "tok_emb = TokenEmbedding(vocab_size, embed_dim)\n",
    "pos_emb = PositionalEmbedding(max_seq_len, embed_dim)\n",
    "mha = MultiHeadAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "ff = FeedForward(embed_dim)\n",
    "ln1 = LayerNorm(embed_dim)\n",
    "ln2 = LayerNorm(embed_dim)\n",
    "\n",
    "x = tok_emb(ids) + pos_emb(ids)\n",
    "\n",
    "mask = create_causal_mask(seq_len, device=x.device)\n",
    "\n",
    "att_out, att_weights = mha(x, mask=mask)\n",
    "x = x + att_out            # residual 1\n",
    "x = ln1(x)\n",
    "\n",
    "ff_out = ff(x)\n",
    "x = x + ff_out             # residual 2\n",
    "x = ln2(x)\n",
    "\n",
    "print(\"Final output shape:\", x.shape)\n",
    "print(\"Attention weights shape:\", att_weights.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-From-Scratch (venv)",
   "language": "python",
   "name": "llm-from-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
